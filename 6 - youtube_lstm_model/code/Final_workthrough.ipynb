{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVP\n",
    "\n",
    "Here, I will outline steps for my MVP, including Data Loading, Data Cleaning, and Preperation of Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get API Key from Google Collab Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Keys import API_KEY\n",
    "\n",
    "API_KEY = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "youtube = build('youtube','v3', developerKey = API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>35.6897</td>\n",
       "      <td>139.6922</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>T≈çky≈ç</td>\n",
       "      <td>primary</td>\n",
       "      <td>37977000.0</td>\n",
       "      <td>1392685764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jakarta</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>-6.2146</td>\n",
       "      <td>106.8451</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>ID</td>\n",
       "      <td>IDN</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>primary</td>\n",
       "      <td>34540000.0</td>\n",
       "      <td>1360771077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>28.6600</td>\n",
       "      <td>77.2300</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>admin</td>\n",
       "      <td>29617000.0</td>\n",
       "      <td>1356872604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>18.9667</td>\n",
       "      <td>72.8333</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>MahƒÅrƒÅshtra</td>\n",
       "      <td>admin</td>\n",
       "      <td>23355000.0</td>\n",
       "      <td>1356226629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manila</td>\n",
       "      <td>Manila</td>\n",
       "      <td>14.6000</td>\n",
       "      <td>120.9833</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>PH</td>\n",
       "      <td>PHL</td>\n",
       "      <td>Manila</td>\n",
       "      <td>primary</td>\n",
       "      <td>23088000.0</td>\n",
       "      <td>1608618140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city city_ascii      lat       lng      country iso2 iso3   admin_name  \\\n",
       "0    Tokyo      Tokyo  35.6897  139.6922        Japan   JP  JPN        T≈çky≈ç   \n",
       "1  Jakarta    Jakarta  -6.2146  106.8451    Indonesia   ID  IDN      Jakarta   \n",
       "2    Delhi      Delhi  28.6600   77.2300        India   IN  IND        Delhi   \n",
       "3   Mumbai     Mumbai  18.9667   72.8333        India   IN  IND  MahƒÅrƒÅshtra   \n",
       "4   Manila     Manila  14.6000  120.9833  Philippines   PH  PHL       Manila   \n",
       "\n",
       "   capital  population          id  \n",
       "0  primary  37977000.0  1392685764  \n",
       "1  primary  34540000.0  1360771077  \n",
       "2    admin  29617000.0  1356872604  \n",
       "3    admin  23355000.0  1356226629  \n",
       "4  primary  23088000.0  1608618140  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_cities = pd.read_csv('worldcities.csv')\n",
    "world_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenhu\\AppData\\Local\\Temp/ipykernel_6756/3597982440.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  world_cities_second = world_cities[20:][world_cities['country'] != 'China']\n"
     ]
    }
   ],
   "source": [
    "world_cities_first = world_cities[0:20]\n",
    "world_cities_second = world_cities[20:][world_cities['country'] != 'China']\n",
    "world_cities = pd.concat((world_cities_first,world_cities_second), axis = 0).reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to pull data from API. We will write a function to do this. There are two steps to this:\n",
    "\n",
    "1. Search: We are searching the most popular videos pertaining to the key word: \"[City name] + travel\". From this, we can obtain the Video ID for the top 50 items.\n",
    "2. Video: From Video ID, we can find the Video title + Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "def search_city(x):\n",
    "\n",
    "    city = x[1]\n",
    "    print(city)\n",
    "    search_list = youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        maxResults = 50,\n",
    "        q=\"travel \" + city,\n",
    "        order = 'viewCount',\n",
    "        type=\"video\"\n",
    "        ).execute()\n",
    "    json_list.append(search_list)\n",
    "    videos = pd.DataFrame(columns = ['video_id','video_title','view_count'])\n",
    "    vid_title_list = []\n",
    "    vid_id_list = []\n",
    "    vid_count_list = []\n",
    "    for i in range(0, len(search_list['items'])):\n",
    "        vid_title_list.append(search_list['items'][i]['snippet']['title'])\n",
    "        \n",
    "        vid_id = search_list['items'][i]['id']['videoId']\n",
    "        vid_id_list.append(vid_id)\n",
    "        \n",
    "        videostats = youtube.videos().list(part = 'statistics', id = vid_id).execute()\n",
    "        vid_count_list.append(videostats['items'][0]['statistics']['viewCount'])\n",
    "        \n",
    "    \n",
    "    vid_data = [vid_id_list, vid_title_list, vid_count_list]\n",
    "    return vid_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to format the data out from the API pull to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amritsar\n",
      "Callao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenhu\\AppData\\Local\\Temp/ipykernel_6756/2564604654.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  world_city_sample['scraped_data'] = world_city_sample.apply(search_city, axis = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligarh\n",
      "Tegucigalpa\n",
      "Ciudad Nezahualcoyotl\n",
      "Tripoli\n",
      "Rostov\n",
      "Nezahualcoyotl\n",
      "Bhiwandi\n",
      "Tbilisi\n",
      "Ufa\n",
      "Fes\n",
      "Sevilla\n",
      "Mexicali\n",
      "Bien Hoa\n",
      "Gwalior\n",
      "Ikare\n",
      "Huambo\n",
      "Salt Lake City\n",
      "Bhilai\n",
      "N'Djamena\n",
      "Irbid\n",
      "Haora\n",
      "Cologne\n",
      "Krasnoyarsk\n",
      "Sao Goncalo\n",
      "Nashville\n",
      "Yerevan\n",
      "Ranchi\n",
      "Nur-Sultan\n",
      "Nouakchott\n",
      "Vereeniging\n",
      "Richmond\n",
      "Sao Luis\n",
      "San Pedro Sula\n",
      "Memphis\n",
      "Goyang\n",
      "Bezwada\n",
      "Edmonton\n",
      "Tunis\n",
      "Barquisimeto\n",
      "Sendai\n",
      "Voronezh\n",
      "Perm\n",
      "Changwon\n",
      "Bogor\n",
      "Raleigh\n",
      "Cartagena\n",
      "Chandigarh\n",
      "Bishkek\n",
      "Matola\n",
      "Ogbomoso\n",
      "Ashgabat\n",
      "Maceio\n",
      "Niamey\n",
      "Managua\n",
      "Patam\n",
      "Tekirdag\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0BdeoItL7a8</td>\n",
       "      <td>THE GOLDEN TEMPLE | AMRITSAR, INDIA</td>\n",
       "      <td>847011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Og1SoLz-FlY</td>\n",
       "      <td>Top 10 Things To Do / See || Amritsar</td>\n",
       "      <td>613244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0tiq1kpV_6U</td>\n",
       "      <td>Amritsar Top 10 Tourist Places In Hindi | Amri...</td>\n",
       "      <td>444569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PfGItt-Fu3M</td>\n",
       "      <td>Punjab is AMAZING | Ep5 Amritsar &amp;amp; The Gol...</td>\n",
       "      <td>396062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5flGGYzh_uE</td>\n",
       "      <td>Amritsar Tourist Places | Amritsar Tour Plan &amp;...</td>\n",
       "      <td>328504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                        video_title view_count\n",
       "0  0BdeoItL7a8                THE GOLDEN TEMPLE | AMRITSAR, INDIA     847011\n",
       "0  Og1SoLz-FlY              Top 10 Things To Do / See || Amritsar     613244\n",
       "0  0tiq1kpV_6U  Amritsar Top 10 Tourist Places In Hindi | Amri...     444569\n",
       "0  PfGItt-Fu3M  Punjab is AMAZING | Ep5 Amritsar &amp; The Gol...     396062\n",
       "0  5flGGYzh_uE  Amritsar Tourist Places | Amritsar Tour Plan &...     328504"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_data = pd.DataFrame(columns = ['video_id','video_title','view_count'])\n",
    "\n",
    "for i in range(332,390,2):\n",
    "    world_city_sample = world_cities.iloc[i:i+2]\n",
    "    world_city_sample['scraped_data'] = world_city_sample.apply(search_city, axis = 1)\n",
    "\n",
    "    for j in range(i, i + world_city_sample.shape[0]):\n",
    "        temp_data = pd.DataFrame(columns = ['video_id','video_title','view_count'])\n",
    "    \n",
    "        temp_data = temp_data.append({'video_id': world_city_sample['scraped_data'].explode().loc[j].iloc[0],\n",
    "                          'video_title': world_city_sample['scraped_data'].explode().loc[j].iloc[1],\n",
    "                          'view_count': world_city_sample['scraped_data'].explode().loc[j].iloc[2]}, ignore_index = True)\n",
    "        world_data = world_data.append(temp_data)\n",
    "\n",
    "world_data_cleaned = world_data.apply(pd.Series.explode)\n",
    "world_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to save these files so I can load them later on. The Youtube API unfortunately has a daily limit, so I make API calls every day and am saving the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_data_cleaned.to_csv('Scraped_Data/world_data_220116.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all files from all API scrapes and combining them all into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filelist(img_folder, filetype = 'csv'):\n",
    "    img_filelist = []\n",
    "    for root, subdirectories, files in os.walk(img_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(filetype):\n",
    "                img_filelist.append(os.path.join(root, file))\n",
    "    return img_filelist\n",
    "\n",
    "file_list = get_filelist('Scraped_Data')\n",
    "\n",
    "files = []\n",
    "for path in file_list:\n",
    "    file = pd.read_csv(path)\n",
    "    files.append(file)\n",
    "\n",
    "files = pd.concat(files, ignore_index=True, join='outer', axis=0)\n",
    "files['video_title'] = files['video_title'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "It's helpful to do some data visualization to look at our data. Here, I'm going to look at the 20 most popular words in my corpus, to see if it makes sense and so I have a better idea of what the popular titles for travel videos look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenhu\\anaconda3\\envs\\mask_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000km</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>002–±</th>\n",
       "      <th>003</th>\n",
       "      <th>004</th>\n",
       "      <th>005—â</th>\n",
       "      <th>006</th>\n",
       "      <th>...</th>\n",
       "      <th>ùêìùêëùêÄùêïùêÑùêã</th>\n",
       "      <th>ùêìùê®</th>\n",
       "      <th>ùêìùê´ùêöùêØùêûùê•</th>\n",
       "      <th>ùêìùê´ùêöùêØùêûùê•ùê¨</th>\n",
       "      <th>ùê¥ùëôùëéùëîùëúùëéùë†</th>\n",
       "      <th>ùê∫ùëúùëñùëéùë†</th>\n",
       "      <th>ùë≠ùíêùíìùíïùíÇùíçùíÜùíõùíÇ</th>\n",
       "      <th>ùë±ùíÇùíëùíÇùíè</th>\n",
       "      <th>ùëªùíìùíÇùíóùíÜùíç</th>\n",
       "      <th>ùëΩùíçùíêùíà</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16613</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16614</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16615 rows √ó 21443 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  000km  001  002  002–±  003  004  005—â  006  ...  ùêìùêëùêÄùêïùêÑùêã  ùêìùê®  \\\n",
       "0       0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "1       0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "2       0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "3       0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "4       0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "...    ..  ...    ...  ...  ...   ...  ...  ...   ...  ...  ...     ...  ..   \n",
       "16610   0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "16611   0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "16612   0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "16613   0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "16614   0    0      0    0    0     0    0    0     0    0  ...       0   0   \n",
       "\n",
       "       ùêìùê´ùêöùêØùêûùê•  ùêìùê´ùêöùêØùêûùê•ùê¨  ùê¥ùëôùëéùëîùëúùëéùë†  ùê∫ùëúùëñùëéùë†  ùë≠ùíêùíìùíïùíÇùíçùíÜùíõùíÇ  ùë±ùíÇùíëùíÇùíè  ùëªùíìùíÇùíóùíÜùíç  ùëΩùíçùíêùíà  \n",
       "0           0        0        0      0          0      0       0     0  \n",
       "1           0        0        0      0          0      0       0     0  \n",
       "2           0        0        0      0          0      0       0     0  \n",
       "3           0        0        0      0          0      0       0     0  \n",
       "4           0        0        0      0          0      0       0     0  \n",
       "...       ...      ...      ...    ...        ...    ...     ...   ...  \n",
       "16610       0        0        0      0          0      0       0     0  \n",
       "16611       0        0        0      0          0      0       0     0  \n",
       "16612       0        0        0      0          0      0       0     0  \n",
       "16613       0        0        0      0          0      0       0     0  \n",
       "16614       0        0        0      0          0      0       0     0  \n",
       "\n",
       "[16615 rows x 21443 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are going to create a document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(files.video_title)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = files.index\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='0'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1130.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_list = data_dtm.sum(axis = 0, skipna = True).sort_values(ascending = False)\n",
    "word_list[0:20]\n",
    "word = pd.DataFrame(word_list[0:20])\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize':(15.7,8.27)})\n",
    "sns.barplot(x = word.index, y = word[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks normal to me for the most part, but a couple things are more random like amp and 39, and those could be errors. So, after this MVP, I will definetely spend more time on data cleaning/preprocessing to clean up my data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data For Modeling\n",
    "\n",
    "For my MVP, I will prepare the data to the format for modeling. In my MVP, I am trying a character prediction. So the prediction will be on what the next character in the sequence is. For my final project, I may try to use word embeddings and a bidirectional LSTM so that I can do word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "alphabet_regular_expression = re.compile(\"[^a-zA-Z]\")\n",
    "\n",
    "def encode_decode(x):\n",
    "    \n",
    "    encoded_string = x.encode(\"ascii\", \"ignore\")\n",
    "    return re.sub(alphabet_regular_expression,\"\", encoded_string.decode().lower())\n",
    "\n",
    "\n",
    "titles = files['video_title']\n",
    "titles  = titles.apply(encode_decode)\n",
    "\n",
    "title_list = list(titles)\n",
    "title_sample = title_list\n",
    "raw_text = ''.join(title_sample) + ' '\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count up all characters in the corpus and make dictionary to map word to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters in the text; corpus length:  921941\n",
      "Total Vocab:  27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text))) #List of every character\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters in the text; corpus length: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define size of dimensions of your variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = n_vocab\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = n_vocab\n",
    "sequence_length = 100\n",
    "hidden_size = 128\n",
    "num_layers = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to standardize the length of each input vector, we need to create sequences that are the same length. For each sentence, we will create sequences of length 30, with shifts of 3 to cover different parts of that sequence. This way we capture a large percentage of each sentence, while still moving through the sentence list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For creating X-Y text input data from each title given:\n",
    "seq_length = 100  #Length of each input sequence\n",
    "step = 3   #Instead of moving 1 letter at a time, try skipping a few.\n",
    "sentences = []    # X values (Sentences)\n",
    "next_chars = []   # Y values. The character that follows the sentence defined as X\n",
    "for title in title_sample:\n",
    "    if seq_length > len(title):\n",
    "        for i in range(0, len(title), step):  #step=1 means each sentence is offset just by a single letter\n",
    "            sentences.append(f\"{title[0: len(title) - i].rjust(seq_length)}\")  #Sequence in\n",
    "            try:\n",
    "                next_chars.append(title[len(title) - i])  #Sequence out\n",
    "            except:\n",
    "                next_chars.append(' ')\n",
    "        n_patterns = len(sentences)\n",
    "    else:\n",
    "        for i in range(0, len(title), step):  #step=1 means each sentence is offset just by a single letter\n",
    "            start_point = len(title) - seq_length - i\n",
    "            if start_point >= 0:\n",
    "                sentences.append(f\"{title[len(title) - seq_length - i: len(title) - i].rjust(seq_length)}\")  #Sequence in\n",
    "            else:\n",
    "                sentences.append(\n",
    "                    f\"{title[0: len(title) - i].rjust(seq_length)}\")  # Sequence in\n",
    "            try:\n",
    "                next_chars.append(title[len(title) - i])  #Sequence out\n",
    "            except:\n",
    "                next_chars.append(' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the sequences into numpy arrays of fixed size, that can be processed by a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313834, 100, 27)\n",
      "(313834, 27)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.zeros((len(sentences), seq_length, n_vocab), dtype=bool)\n",
    "y = np.zeros((len(sentences), n_vocab), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[next_chars[i]]] = 1\n",
    "\n",
    "x = x.astype('float32')\n",
    "y = y.astype('float32')\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use custom DataSet and DataLoader to structure data and load to model in increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        sample = {\"x\": x, \"y\": y}\n",
    "        return sample\n",
    "\n",
    "t_DS = TextDataset(X_train,y_train)\n",
    "loader = DataLoader(t_DS ,batch_size = 256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Training\n",
    "\n",
    "Create RNN class first, can try LSTM and GRU architecture later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        #self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)  \n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        #out = self.softmax(out)\n",
    "        # out: (n, 10)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        #self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        #out, _ = self.lstm(x, h0)  \n",
    "        # or:\n",
    "        out, _ = self.lstm(x, (h0,c0))\n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        #out = self.softmax(out)\n",
    "        # out: (n, 10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        #self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.gru(x, h0)  \n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        #out = self.softmax(out)\n",
    "        # out: (n, 10)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model object from RNN class, then specify training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, RMSprop\n",
    "from tqdm import tqdm\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=0.001)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training Loop for specified amount of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss : 2.516052722930908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss : 2.3012382984161377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss : 2.1549429893493652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss : 2.04616117477417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss : 1.9388805627822876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss : 1.851061224937439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss : 1.7520618438720703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss : 1.6670738458633423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss : 1.597827434539795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss : 1.5475162267684937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss : 1.5025997161865234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss : 1.4393850564956665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss : 1.3705049753189087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss : 1.2939780950546265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss : 1.2149131298065186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss : 1.1764531135559082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss : 1.1361521482467651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss : 1.06533944606781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss : 1.033179759979248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss : 0.9815126657485962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss : 0.9672287106513977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss : 0.93413245677948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss : 0.9076480865478516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss : 0.8745600581169128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss : 0.8531128764152527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss : 0.8199025392532349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss : 0.7909573912620544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss : 0.7820140719413757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss : 0.7413816452026367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss : 0.756412148475647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Loss : 0.7359917759895325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Loss : 0.7565248012542725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Loss : 0.7471620440483093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Loss : 0.7574394345283508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Loss : 0.751645028591156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Loss : 0.7078405618667603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Loss : 0.6992992162704468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Loss : 0.6687524914741516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss : 0.6641650795936584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Loss : 0.642357587814331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Loss : 0.7007085680961609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Loss : 0.6272953748703003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Loss : 0.6434057950973511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss : 0.6002674698829651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Loss : 0.60325026512146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Loss : 0.5472723245620728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Loss : 0.5399752855300903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Loss : 0.5318522453308105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Loss : 0.5172843933105469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Loss : 0.5001539587974548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Loss : 0.5053878426551819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Loss : 0.5455977320671082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Loss : 0.544485330581665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Loss : 0.5100724697113037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Loss : 0.4760521948337555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Loss : 0.5159765481948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Loss : 0.4868182837963104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Loss : 0.5156821608543396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Loss : 0.4122600853443146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Loss : 0.48033028841018677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Loss : 0.4575497806072235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Loss : 0.44467246532440186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Loss : 0.4817295968532562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Loss : 0.4640929102897644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Loss : 0.5214649438858032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Loss : 0.4498595595359802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Loss : 0.42863360047340393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Loss : 0.4197321832180023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Loss : 0.41431233286857605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Loss : 0.4475448727607727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Loss : 0.37283194065093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Loss : 0.41104787588119507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 37.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Loss : 0.3627680838108063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:26, 37.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Loss : 0.3646409213542938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Loss : 0.38921794295310974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Loss : 0.35861942172050476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Loss : 0.3755281865596771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Loss : 0.3527972102165222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Loss : 0.3907797932624817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Loss : 0.3678535521030426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Loss : 0.30625274777412415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Loss : 0.3871231973171234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Loss : 0.38736337423324585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Loss : 0.33576521277427673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Loss : 0.37777936458587646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Loss : 0.34289607405662537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Loss : 0.3423638343811035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Loss : 0.34023505449295044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Loss : 0.35368576645851135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Loss : 0.609477162361145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Loss : 0.4278314411640167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Loss : 0.3069855868816376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Loss : 0.30794668197631836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Loss : 0.34849050641059875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Loss : 0.33264631032943726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Loss : 0.32492154836654663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Loss : 0.3654658794403076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Loss : 0.3312154710292816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Loss : 0.3042057454586029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Loss : 0.31878527998924255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 Loss : 0.2969978451728821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 Loss : 0.296688973903656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 Loss : 0.33944958448410034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 Loss : 0.32738497853279114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:26, 37.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Loss : 0.3766142427921295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 Loss : 0.35272926092147827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 Loss : 0.3036966323852539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 Loss : 0.34852176904678345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 Loss : 0.2568229138851166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 Loss : 0.3222510516643524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 Loss : 0.3726006746292114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 Loss : 0.29310837388038635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:26, 37.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 Loss : 0.26033729314804077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 Loss : 0.26559028029441833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 Loss : 0.2984071373939514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 Loss : 0.3352397680282593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:26, 37.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 Loss : 0.2909165620803833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 Loss : 0.30562371015548706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:26, 37.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 Loss : 0.28318601846694946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 Loss : 0.3147442638874054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 Loss : 0.301831990480423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 Loss : 0.351779967546463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 37.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 Loss : 0.2582119107246399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:26, 37.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 Loss : 0.29497241973876953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 Loss : 0.3179934620857239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 Loss : 0.31544992327690125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 Loss : 0.3034929037094116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 Loss : 0.2997661828994751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 Loss : 0.32600197196006775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 Loss : 0.3118661642074585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 Loss : 0.23122897744178772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 Loss : 0.2392439842224121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133 Loss : 0.24232779443264008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 Loss : 0.28437095880508423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 Loss : 0.2960241734981537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 Loss : 0.3349132537841797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 Loss : 0.2814907133579254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 Loss : 0.23638300597667694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 Loss : 0.3246980905532837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 Loss : 0.3141261041164398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141 Loss : 0.3361186683177948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 Loss : 0.26920396089553833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143 Loss : 0.3195820450782776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 Loss : 0.3451942801475525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 Loss : 0.30971020460128784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:24, 39.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 Loss : 0.2801271677017212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:26, 37.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147 Loss : 0.2871032953262329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 39.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 Loss : 0.3313862979412079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:26, 37.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 Loss : 0.2782670259475708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [00:25, 38.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 Loss : 0.23591884970664978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for i, data in tqdm(enumerate(loader)):\n",
    "        x_train_m, y_train_m = data['x'], data['y']\n",
    "        x_train_m = x_train_m.to(device)\n",
    "        y_train_m = y_train_m.to(device)\n",
    "\n",
    "        outputs = model_lstm(x_train_m)\n",
    "        loss = criterion(outputs, y_train_m)\n",
    "        loss_list.append(loss)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch {} Loss : {}'.format((epoch+1),loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Still in progress, need further training, and to fix testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_set = x[0:5000,:,:]\n",
    "y_test_set = y[0:5000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DS = TextDataset(X_test,y_test)\n",
    "test_loader = DataLoader(test_DS ,batch_size = 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g',\n",
       " ' ',\n",
       " 'g',\n",
       " 'g',\n",
       " 'e',\n",
       " 'v',\n",
       " 'l',\n",
       " ' ',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " ' ',\n",
       " 'd',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 'r',\n",
       " 'f',\n",
       " 'd',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 'n',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " 'a',\n",
       " 't',\n",
       " 'a',\n",
       " 'r',\n",
       " 'n',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'c',\n",
       " 'g',\n",
       " 'a',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 't',\n",
       " 'v',\n",
       " 'a',\n",
       " 'o',\n",
       " 'l',\n",
       " 'o',\n",
       " 'i',\n",
       " 'e',\n",
       " 'd',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 't',\n",
       " 'l',\n",
       " 'o',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'a',\n",
       " 'd',\n",
       " ' ',\n",
       " 's',\n",
       " 'l',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'e',\n",
       " 'n',\n",
       " 'h',\n",
       " 't',\n",
       " 'o',\n",
       " 't',\n",
       " 'a',\n",
       " ' ',\n",
       " 'l',\n",
       " 'g',\n",
       " 'r',\n",
       " 'c',\n",
       " 'a',\n",
       " 'o',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'e',\n",
       " 't',\n",
       " 'n',\n",
       " 'y',\n",
       " 'i',\n",
       " 'i',\n",
       " 'a',\n",
       " 's',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'a',\n",
       " 'e',\n",
       " 'n',\n",
       " 'l',\n",
       " 's',\n",
       " 'l',\n",
       " 'd',\n",
       " 'a',\n",
       " 'f',\n",
       " ' ',\n",
       " 'i',\n",
       " 'r',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'e',\n",
       " 's',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " 'o',\n",
       " 'i',\n",
       " 'e',\n",
       " ' ',\n",
       " 'g',\n",
       " 'd',\n",
       " 'k',\n",
       " 'a',\n",
       " 't',\n",
       " 'n',\n",
       " 'x',\n",
       " 'n',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 's',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 'f',\n",
       " 'o',\n",
       " 'e',\n",
       " ' ',\n",
       " 'y',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'v',\n",
       " 'o',\n",
       " 'h',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 'n',\n",
       " 't',\n",
       " 'n',\n",
       " 't',\n",
       " 'l',\n",
       " 'n',\n",
       " 'r',\n",
       " 'n',\n",
       " 'r',\n",
       " 'n',\n",
       " 'r',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " 's',\n",
       " 'o']"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predictions(outputs):\n",
    "    filtered_output = np.zeros_like(outputs)\n",
    "    filtered_output[np.arange(len(outputs)), outputs.argmax(1)] = 1\n",
    "    final_int = filtered_output.argmax(axis = 1)\n",
    "    predictions = []\n",
    "    for letter in final_int:\n",
    "        predictions.append(int_to_char[letter])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "get_predictions(outputs.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_second(outputs):\n",
    "    filtered_output = np.zeros_like(outputs)\n",
    "    filtered_output[np.arange(len(outputs)), outputs.argmax(1)] = 1\n",
    "    final_int = np.argsort(filtered_output, axis=1)[:,-1]\n",
    "    return final_int\n",
    "\n",
    "get_predictions_second(outputs.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for i, data in tqdm(enumerate(test_loader)):\n",
    "        x_test_m, y_test_m = data['x'], data['y']\n",
    "        x_test_m = x_test_m.to(device)\n",
    "        y_test_m = y_test_m.to(device)\n",
    "        outputs = model_lstm(x_test_m).cpu().numpy()\n",
    "        filtered_output = np.zeros_like(outputs)\n",
    "        filtered_output[np.arange(len(outputs)), outputs.argmax(1)] = 1\n",
    "        \n",
    "        #_, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += y_test_m.size(0)\n",
    "        n_correct += np.sum(np.array(get_predictions(filtered_output)) == np.array(get_predictions(y_test_m.cpu().numpy())))\n",
    "\n",
    "\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(get_predictions(filtered_output)) == np.array(get_predictions(y_test_m.cpu().numpy())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_predictions_matrix (__main__.TestFunctions) ... ok\n",
      "test_second (__main__.TestFunctions) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_second (__main__.TestFunctions)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kenhu\\AppData\\Local\\Temp/ipykernel_11888/2031806237.py\", line 7, in test_second\n",
      "    assert type(get_predictions_second(outputs)) is int\n",
      "AssertionError\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2639af88610>"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest \n",
    "class TestFunctions(unittest.TestCase): \n",
    "    def test_predictions_matrix(self): \n",
    "        assert len(get_predictions(outputs)) == outputs.shape[0]\n",
    "\n",
    "    def test_second(self):\n",
    "        assert type(get_predictions_second(outputs)) is int\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'roadtrip'\n",
    "sentence = sentence.rjust(seq_length)\n",
    "generated = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vodagemukahipalingtheiltingshorts ocitilesandomentssortsinro                                                                                            roadtripvodagemukahipalingtheiltingshorts ocitilesandomentssortsinro\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "for i in range(60):   # Number of characters including spaces\n",
    "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_to_int[char]] = 1.\n",
    "    x_pred = x_pred.astype('float32')\n",
    "    x_pred = torch.from_numpy(x_pred).to(device)\n",
    "    preds = model_lstm(x_pred).cpu().detach().numpy()\n",
    "    #print(preds)\n",
    "    next_char = get_predictions(preds)[0]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print(generated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.473044  , -1.6067774 , -4.8023868 , -6.0202785 , -7.410056  ,\n",
       "        -1.177187  , -4.3759823 , -2.3694432 , -5.0864434 , -5.686878  ,\n",
       "        -0.73352265, -1.9418195 , -1.0261691 , -1.908966  , -3.4814541 ,\n",
       "        -2.6615489 , -2.4907494 , -1.8747177 , -3.0576973 , -2.6913378 ,\n",
       "        -2.9519777 , -2.448581  , -2.315035  , -2.8207023 , -1.876294  ,\n",
       "        -9.371428  , -7.016985  , -3.2558498 , -5.334759  , -5.101123  ,\n",
       "        -4.7987666 , -5.320304  , -8.154394  , -5.178426  , -6.9275665 ,\n",
       "         0.2309207 ,  1.0595065 ,  2.1929283 ,  0.98417896, -1.1793524 ,\n",
       "         2.2904058 ,  1.9806143 ,  0.3018907 , -0.8691815 , -2.2329247 ,\n",
       "         0.3834435 , -1.0320481 ,  2.0991518 ,  3.6967103 ,  1.8505684 ,\n",
       "         2.6434188 , -3.0986857 ,  3.3486764 ,  1.7970933 ,  0.36995444,\n",
       "         2.5554717 ,  2.3016772 ,  3.2990541 ,  0.32242757, -0.4407666 ,\n",
       "        -1.6383371 , -8.762027  , -2.2224083 , -7.8601203 , -6.4827514 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.cpu().detach().numpy()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca49a2798dd97d70832bdc8ff752388fc01aafdd5bee2aee67cb6443662c1acd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('mask_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
